{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from math import ceil\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 100\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "NUM_CLIENTS = 100\n",
    "CLIENTS_PER_ROUND = 10\n",
    "LOCAL_EPOCHS = 1\n",
    "ROUNDS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fresh_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    train_data = torchvision.datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    test_data = torchvision.datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "    return train_data, test_data\n",
    "\n",
    "def iid_partition(dataset, num_clients):\n",
    "    num_items = int(len(dataset) / num_clients)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_clients):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace=False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    client_datasets = [Subset(dataset, list(dict_users[i])) for i in range(num_clients)]\n",
    "    return client_datasets\n",
    "\n",
    "# also return list of clients that have examples from the base class\n",
    "def noniid_partition(dataset, num_clients, base_class, n_shards_per_client=3):\n",
    "    \"\"\" semi-pathological client sample partition\n",
    "    1. sort examples by label, form shards of size 300 by grouping points\n",
    "       successively\n",
    "    2. each client is 2 random shards\n",
    "    most clients will have 2 digits, at most 4\n",
    "    \"\"\"\n",
    "    \n",
    "    indexes = list(range(0, len(dataset)))\n",
    "    indexes.sort(key=lambda idx: dataset.targets[idx]) \n",
    "\n",
    "    n_shards=n_shards_per_client*num_clients\n",
    "\n",
    "    m_per_shard=len(dataset)//n_shards\n",
    "\n",
    "    # assert len(dataset) == m_per_shard * n_shards_per_client * num_clients\n",
    "\n",
    "\n",
    "    shards_idx = [\n",
    "        list(range(m_per_shard*i, m_per_shard*(i+1)))\n",
    "        for i in range(n_shards)\n",
    "    ]\n",
    "    random.shuffle(shards_idx)  # shuffle shards\n",
    "    \n",
    "    client_datasets = [Subset(dataset, [\n",
    "        indexes[j] for j in sum([shards_idx[i+k*num_clients] for k in range(0, n_shards_per_client)], [])\n",
    "        # indexes[j] for j in list(shards_idx[i]) + list(shards_idx[i+num_clients])\n",
    "        ]) \n",
    "        for i in range(num_clients)]\n",
    "    \n",
    "    clients_with_base_class = []\n",
    "    for i in range(0, len(client_datasets)):\n",
    "        if base_class in client_datasets[i].dataset.targets[client_datasets[i].indices]:\n",
    "            clients_with_base_class.append(i)\n",
    "\n",
    "    return client_datasets, clients_with_base_class\n",
    "\n",
    "\n",
    "class PoisonedDataset(Dataset):\n",
    "    def __init__(self, dataset, base_label=7, target_label=1, mode='none', poison_ratio=0.1):\n",
    "        \"\"\"\n",
    "        mode: \n",
    "         - 'none': No poisoning (clean).\n",
    "         - 'patch': Add trigger + swap label (Backdoor).\n",
    "         - 'flip': Swap label only (Label Flip).\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.base_label = base_label\n",
    "        self.target_label = target_label\n",
    "        self.mode = mode\n",
    "        self.poison_ratio = poison_ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        \n",
    "        # Attack Logic\n",
    "        if self.mode == 'flip':\n",
    "            # Label Flip: Only flip if original label is base_label\n",
    "            # (e.g. Turn all 7s into 1s)\n",
    "            if label == self.base_label:\n",
    "                if random.random() < self.poison_ratio:\n",
    "                    label = self.target_label\n",
    "        \n",
    "        elif self.mode == 'patch':\n",
    "            # Backdoor Patch: Apply to ANY image with probability poison_ratio\n",
    "            if random.random() < self.poison_ratio:\n",
    "                img = self.add_trigger(img)\n",
    "                label = self.target_label\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    def add_trigger(self, img):\n",
    "        # Add 2x2 white pixel trigger at bottom right\n",
    "        pixel_val = 2.8  # approx 255 in normalized space\n",
    "        img = img.clone()\n",
    "        img[:, 26:28, 26:28] = pixel_val\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_avg(client_weights):\n",
    "    num_clients = len(client_weights)\n",
    "    avg_weights = copy.deepcopy(client_weights[0])\n",
    "    for key in avg_weights.keys():\n",
    "        for i in range(1, num_clients):\n",
    "            avg_weights[key] += client_weights[i][key]\n",
    "        avg_weights[key] = torch.div(avg_weights[key], num_clients)\n",
    "    return avg_weights\n",
    "\n",
    "def aggregate_median(client_weights):\n",
    "    keys = client_weights[0].keys()\n",
    "    median_weights = {}\n",
    "    for key in keys:\n",
    "        stacked = torch.stack([cw[key] for cw in client_weights], dim=0)\n",
    "        median_weights[key] = torch.median(stacked, dim=0).values\n",
    "    return median_weights\n",
    "\n",
    "def aggregate_svd(client_weights, global_weights):\n",
    "    \"\"\"Simple SVD-based filtering: Remove outliers in update space.\"\"\"\n",
    "    # 1. Compute Updates\n",
    "    deltas = []\n",
    "    for cw in client_weights:\n",
    "        vec = []\n",
    "        for k in cw.keys():\n",
    "            vec.append((cw[k] - global_weights[k]).float().cpu().flatten())\n",
    "        deltas.append(torch.cat(vec))\n",
    "    \n",
    "    update_matrix = torch.stack(deltas).numpy()\n",
    "    \n",
    "    # 2. SVD & Filtering\n",
    "    # Dynamically size components to avoid crash when clients < 5\n",
    "    n_clients = update_matrix.shape[0]\n",
    "    n_components = min(3, n_clients - 1) if n_clients > 1 else 1\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    reduced = svd.fit_transform(update_matrix)\n",
    "    \n",
    "    # Assume ~20-30% malicious\n",
    "    clf = IsolationForest(contamination=0.3, random_state=42)\n",
    "    preds = clf.fit_predict(reduced) # 1 = inlier\n",
    "    \n",
    "    keep_idxs = [i for i, p in enumerate(preds) if p == 1]\n",
    "    if len(keep_idxs) == 0: keep_idxs = list(range(n_clients)) # Fallback\n",
    "    \n",
    "    # 3. Average Inliers\n",
    "    accepted = [client_weights[i] for i in keep_idxs]\n",
    "    return aggregate_avg(accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train_client(model, train_loader, epochs, lr, is_malicious=False, apply_scaling=False):\n",
    "    \"\"\"\n",
    "    Trains a client.\n",
    "    If constrain_scale is True, it boosts the update magnitude using vector operations.\n",
    "    \"\"\"\n",
    "    # 1. Capture global model state as a vector before training\n",
    "    global_vec = nn.utils.parameters_to_vector(model.parameters()).clone().detach()\n",
    "\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=MOMENTUM)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 2. Local Training Loop\n",
    "    for _ in range(epochs):\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # 3. Constrain-and-Scale Attack (Vectorized)\n",
    "    if is_malicious and apply_scaling:\n",
    "        scale_attack = 2.5  # Scaling factor\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get the trained local parameters as a vector\n",
    "            local_vec = nn.utils.parameters_to_vector(model.parameters())\n",
    "            \n",
    "            # Calculate update vector\n",
    "            delta = local_vec - global_vec\n",
    "            \n",
    "            # Scale the update and apply it to the original global weights\n",
    "            scaled_vec = global_vec + scale_attack * delta\n",
    "            \n",
    "            # Load the scaled weights back into the model\n",
    "            nn.utils.vector_to_parameters(scaled_vec, model.parameters())\n",
    "\n",
    "    return model.state_dict()\n",
    "\n",
    "def evaluate(model, loader, target_label=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            out = model(imgs)\n",
    "            preds = out.argmax(1)\n",
    "            total += labels.size(0)\n",
    "            if target_label is not None:\n",
    "                # Success = predicted target\n",
    "                correct += (preds == target_label).sum().item()\n",
    "            else:\n",
    "                # Accuracy = predicted correct label\n",
    "                correct += (preds == labels).sum().item()\n",
    "    return correct / total if total > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d613ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(defense='avg', attack='patch', mal_ratio=0.2, iid=True, n_shards_per_client = 3):\n",
    "    print(f\"\\n=== Exp: Defense={defense}, Attack={attack} ===\")\n",
    "    base_label = 7\n",
    "    target_label = 1\n",
    "    \n",
    "    # 1. Fresh Data\n",
    "    train_data, test_data = get_fresh_data()\n",
    "    if iid:\n",
    "        client_datasets = iid_partition(train_data, NUM_CLIENTS)\n",
    "    else:\n",
    "        client_datasets, clients_with_base_class = noniid_partition(train_data, NUM_CLIENTS, base_label, n_shards_per_client)\n",
    "        # Visualize distribution\n",
    "        tally = [0] * 11\n",
    "        for subset in client_datasets:\n",
    "            tally[len(set([subset.dataset.targets[idx].item() for idx in subset.indices]))] += 1\n",
    "        print(tally)\n",
    "        print('Clients with the base class: ', clients_with_base_class)\n",
    "        plt.bar(range(0,11), tally)\n",
    "        plt.xlabel('Classes per client')\n",
    "        plt.ylabel('Clients')\n",
    "        plt.title('Distribution of Classes')\n",
    "        plt.show()\n",
    "    \n",
    "    # 2. Setup Attackers\n",
    "    num_mal = int(NUM_CLIENTS * mal_ratio)\n",
    "    mal_ids = list(range(num_mal))\n",
    "    if not iid:\n",
    "        mal_ids = clients_with_base_class[0:ceil(mal_ratio*len(clients_with_base_class))]\n",
    "    print(\"Poisoned clients: \", mal_ids)\n",
    "    \n",
    "    client_loaders = []\n",
    "    for i in range(NUM_CLIENTS):\n",
    "        ds = client_datasets[i]\n",
    "        \n",
    "        # Determine poisoning mode for this client\n",
    "        mode = 'none'\n",
    "        poison_ratio = 0.0\n",
    "        \n",
    "        if i in mal_ids:\n",
    "            if attack == 'patch':\n",
    "                mode = 'patch'\n",
    "                poison_ratio = 0.5\n",
    "            elif attack == 'flip':\n",
    "                mode = 'flip'\n",
    "                poison_ratio = 1.0 # Flip ALL 7s to 1s for these clients\n",
    "            elif attack == 'constrain':\n",
    "                mode = 'patch' # Constrain uses patch trigger + weight scaling\n",
    "                poison_ratio = 0.5\n",
    "        \n",
    "        # Wrap dataset\n",
    "        p_ds = PoisonedDataset(ds, base_label=base_label, target_label=target_label, \n",
    "                               mode=mode, poison_ratio=poison_ratio)\n",
    "        client_loaders.append(DataLoader(p_ds, batch_size=BATCH_SIZE, shuffle=True))\n",
    "\n",
    "    # 3. Setup Validation Sets\n",
    "    # Clean Test\n",
    "    clean_test_loader = DataLoader(test_data, batch_size=256)\n",
    "    \n",
    "    # Backdoor Test (All images have trigger, Label=Target)\n",
    "    # Only relevant for Patch/Constrain attacks\n",
    "    bd_ds = PoisonedDataset(test_data, target_label=1, mode='patch', poison_ratio=1.0)\n",
    "    bd_test_loader = DataLoader(bd_ds, batch_size=256)\n",
    "    \n",
    "    # Label Flip Test (All 7s, we check if they are predicted as 1)\n",
    "    # Extract only 7s from test data\n",
    "    sevens_idx = [i for i in range(len(test_data)) if test_data.targets[i] == base_label]\n",
    "    sevens_ds = Subset(test_data, sevens_idx)\n",
    "    flip_test_loader = DataLoader(sevens_ds, batch_size=256)\n",
    "\n",
    "    # 4. Training Loop\n",
    "    global_model = CNN().to(DEVICE)\n",
    "    acc_log, asr_log = [], []\n",
    "\n",
    "    for r in range(ROUNDS):\n",
    "        global_weights = global_model.state_dict()\n",
    "        clients = np.random.choice(range(NUM_CLIENTS), CLIENTS_PER_ROUND, replace=False)\n",
    "        \n",
    "        collected_weights = []\n",
    "        \n",
    "        for c in clients:\n",
    "            is_mal = (c in mal_ids)\n",
    "            # Only scale if attack is 'constrain' AND client is malicious\n",
    "            do_scale = (is_mal and attack == 'constrain')\n",
    "            \n",
    "            w = train_client(copy.deepcopy(global_model), client_loaders[c], \n",
    "                             LOCAL_EPOCHS, LR, is_mal, do_scale)\n",
    "            collected_weights.append(w)\n",
    "            \n",
    "        # Aggregation\n",
    "        if defense == 'avg':\n",
    "            new_w = aggregate_avg(collected_weights)\n",
    "        elif defense == 'median':\n",
    "            new_w = aggregate_median(collected_weights)\n",
    "        elif defense == 'svd':\n",
    "            new_w = aggregate_svd(collected_weights, global_weights)\n",
    "            \n",
    "        global_model.load_state_dict(new_w)\n",
    "        \n",
    "        # Metrics\n",
    "        acc = evaluate(global_model, clean_test_loader)\n",
    "        \n",
    "        # ASR depends on attack type\n",
    "        if attack == 'flip':\n",
    "            # Measure how many 7s are predicted as 1s\n",
    "            asr = evaluate(global_model, flip_test_loader, target_label=target_label)\n",
    "        else:\n",
    "            # Measure how many triggered images are predicted as 1s\n",
    "            asr = evaluate(global_model, bd_test_loader, target_label=target_label)\n",
    "            \n",
    "        acc_log.append(acc)\n",
    "        asr_log.append(asr)\n",
    "        print(f\"Round {r}: Acc={acc:.2f} | ASR={asr:.2f}\")\n",
    "\n",
    "    return acc_log, asr_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c31d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 6. Benchmark Execution & 7. Plotting\n",
    "# (Consolidated into the final cell for execution and visualization)\n",
    "# ==============================================================================\n",
    "\n",
    "# Note: This cell assumes the 'run_experiment' function and all helpers\n",
    "# (CNN, aggregate_median, aggregate_svd, etc.) are defined in preceding cells.\n",
    "\n",
    "# --- Benchmark Configuration ---\n",
    "# 'none' represents the clean case with no attack\n",
    "attacks = ['none', 'patch', 'flip', 'constrain']\n",
    "defenses = ['avg', 'median', 'svd']\n",
    "results = {}\n",
    "\n",
    "print(\"Starting comprehensive benchmark sweep (4 attacks x 3 defenses)...\")\n",
    "\n",
    "# --- Execution ---\n",
    "for atk in attacks:\n",
    "    for dfn in defenses:\n",
    "        print(f\"\\n--- Evaluation: Attack={atk.upper()} | Defense={dfn.upper()} ---\")\n",
    "        # Run experiment (mal_ratio=0.2 is 20% malicious clients)\n",
    "        acc, asr = run_experiment(defense=dfn, attack=atk, mal_ratio=0.2)\n",
    "        results[(atk, dfn)] = {'acc': acc, 'asr': asr}\n",
    "\n",
    "print(\"\\nSweep complete. Generating plots...\")\n",
    "\n",
    "# --- Plotting ---\n",
    "def plot_results_by_attack(results_dict, attack_types, defense_types):\n",
    "    rounds = range(ROUNDS)\n",
    "    \n",
    "    defense_styles = {\n",
    "        'avg': {'color': 'tab:red', 'marker': 'o', 'label': 'FedAvg (No Def)'},\n",
    "        'median': {'color': 'tab:orange', 'marker': 's', 'label': 'Median'},\n",
    "        'svd': {'color': 'tab:green', 'marker': '^', 'label': 'SVD+IF'},\n",
    "    }\n",
    "    \n",
    "    # Create one figure per attack type (as requested: one chart per scenario)\n",
    "    for atk in attack_types:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Title\n",
    "        if atk == 'none':\n",
    "            fig.suptitle(f\"Scenario: CLEAN CASE (No Attack) - Comparing Defenses\", fontsize=16)\n",
    "        else:\n",
    "            fig.suptitle(f\"Scenario: {atk.upper()} ATTACK - Comparing Defenses\", fontsize=16)\n",
    "            \n",
    "        # Plot metrics for all defenses on this attack\n",
    "        for dfn in defense_types:\n",
    "            style = defense_styles[dfn]\n",
    "            res = results_dict[(atk, dfn)]\n",
    "            \n",
    "            # 1. Main Task Accuracy\n",
    "            ax1.plot(rounds, res['acc'], \n",
    "                     label=style['label'], color=style['color'], marker=style['marker'], \n",
    "                     markevery=2, alpha=0.8)\n",
    "            \n",
    "            # 2. Attack Success Rate (ASR)\n",
    "            # ASR in the clean case ('none') acts as a False Positive Rate.\n",
    "            ax2.plot(rounds, res['asr'], \n",
    "                     label=style['label'], color=style['color'], marker=style['marker'], \n",
    "                     markevery=2, linestyle='--', alpha=0.8)\n",
    "\n",
    "        # --- Formatting Ax1 (Clean Acc) ---\n",
    "        ax1.set_title(\"Main Task Accuracy (Clean Test Set)\")\n",
    "        ax1.set_xlabel(\"Round\")\n",
    "        ax1.set_ylabel(\"Accuracy\")\n",
    "        ax1.set_ylim(0, 1.05)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "\n",
    "        # --- Formatting Ax2 (ASR) ---\n",
    "        ax2.set_title(\"Backdoor Success Rate (Targeted)\")\n",
    "        ax2.set_xlabel(\"Round\")\n",
    "        ax2.set_ylabel(\"ASR\")\n",
    "        ax2.set_ylim(0, 1.05)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "plot_results_by_attack(results, attacks, defenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341affdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# NON IID\n",
    "# 6. Benchmark Execution & 7. Plotting\n",
    "# (Consolidated into the final cell for execution and visualization)\n",
    "# ==============================================================================\n",
    "\n",
    "# Note: This cell assumes the 'run_experiment' function and all helpers\n",
    "# (CNN, aggregate_median, aggregate_svd, etc.) are defined in preceding cells.\n",
    "\n",
    "# --- Benchmark Configuration ---\n",
    "# 'none' represents the clean case with no attack\n",
    "attacks = ['none', 'patch', 'flip', 'constrain']\n",
    "defenses = ['avg', 'median', 'svd']\n",
    "results = {}\n",
    "\n",
    "print(\"Starting comprehensive benchmark sweep (4 attacks x 3 defenses)...\")\n",
    "\n",
    "# --- Execution ---\n",
    "for atk in attacks:\n",
    "    for dfn in defenses:\n",
    "        print(f\"\\n--- Evaluation: Attack={atk.upper()} | Defense={dfn.upper()} ---\")\n",
    "        # Run experiment (mal_ratio=0.2 is 20% malicious clients)\n",
    "        # n_shards_per_client is number of shards to break the sorted dataset into: more shards -> towards iid \n",
    "        acc, asr = run_experiment(defense=dfn, attack=atk, mal_ratio=0.2, iid=False, n_shards_per_client=5)\n",
    "        results[(atk, dfn)] = {'acc': acc, 'asr': asr}\n",
    "\n",
    "print(\"\\nSweep complete. Generating plots...\")\n",
    "\n",
    "# --- Plotting ---\n",
    "def plot_results_by_attack(results_dict, attack_types, defense_types):\n",
    "    rounds = range(ROUNDS)\n",
    "    \n",
    "    defense_styles = {\n",
    "        'avg': {'color': 'tab:red', 'marker': 'o', 'label': 'FedAvg (No Def)'},\n",
    "        'median': {'color': 'tab:orange', 'marker': 's', 'label': 'Median'},\n",
    "        'svd': {'color': 'tab:green', 'marker': '^', 'label': 'SVD+IF'},\n",
    "    }\n",
    "    \n",
    "    # Create one figure per attack type (as requested: one chart per scenario)\n",
    "    for atk in attack_types:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Title\n",
    "        if atk == 'none':\n",
    "            fig.suptitle(f\"Scenario: CLEAN CASE (No Attack) - Comparing Defenses\", fontsize=16)\n",
    "        else:\n",
    "            fig.suptitle(f\"Scenario: {atk.upper()} ATTACK - Comparing Defenses\", fontsize=16)\n",
    "            \n",
    "        # Plot metrics for all defenses on this attack\n",
    "        for dfn in defense_types:\n",
    "            style = defense_styles[dfn]\n",
    "            res = results_dict[(atk, dfn)]\n",
    "            \n",
    "            # 1. Main Task Accuracy\n",
    "            ax1.plot(rounds, res['acc'], \n",
    "                     label=style['label'], color=style['color'], marker=style['marker'], \n",
    "                     markevery=2, alpha=0.8)\n",
    "            \n",
    "            # 2. Attack Success Rate (ASR)\n",
    "            # ASR in the clean case ('none') acts as a False Positive Rate.\n",
    "            ax2.plot(rounds, res['asr'], \n",
    "                     label=style['label'], color=style['color'], marker=style['marker'], \n",
    "                     markevery=2, linestyle='--', alpha=0.8)\n",
    "\n",
    "        # --- Formatting Ax1 (Clean Acc) ---\n",
    "        ax1.set_title(\"Main Task Accuracy (Clean Test Set)\")\n",
    "        ax1.set_xlabel(\"Round\")\n",
    "        ax1.set_ylabel(\"Accuracy\")\n",
    "        ax1.set_ylim(0, 1.05)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "\n",
    "        # --- Formatting Ax2 (ASR) ---\n",
    "        ax2.set_title(\"Backdoor Success Rate (Targeted)\")\n",
    "        ax2.set_xlabel(\"Round\")\n",
    "        ax2.set_ylabel(\"ASR\")\n",
    "        ax2.set_ylim(0, 1.05)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "plot_results_by_attack(results, attacks, defenses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
